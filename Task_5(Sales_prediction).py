# -*- coding: utf-8 -*-
"""Sales Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YFMwhvJ5pjlXGiillss08xG3sdObsnHG

**Sales Prediction using Python**

Data Collection

Importing pandas library for accessing the data
"""

import pandas as pd

a=pd.read_csv('https://docs.google.com/spreadsheets/d/11tF6SH9oeHXPVfJRICUfX6NwlxS9D_eKfrbNPCoof0M/export?format=csv&gid=0')

"""Data Organization"""

a.head(3)

a.tail(3)

"""Getting the data's info/summary"""

a.info()

a.describe()

"""Data Cleaning

Checking for null values
"""

a.isnull().sum()

"""Checking for duplicates"""

a.duplicated()

"""Exploratory Data Analysis"""

#importing libraries for EDA
import seaborn as sns
import matplotlib.pyplot as plt

sns.scatterplot(data=a,x='TV',y='Newspaper')

"""Data Preparation - removing outliers

"""

a[(a['TV']>50) & (a['Newspaper']>100)]

a=a.drop(index=16)

i=[]
for x in range(0,len(a)):
  i.append(x)
a.index=i

a1=sns.scatterplot(data=a,x='TV',y='Newspaper')
print(a1)

# Checking the relationship between TV and Sales
sns.scatterplot(x='TV',y='Sales',data=a)

"""The above graph shows, as the TV values increases, Sales also increases linearly"""

sns.displot(x=a['Sales'])

"""The distribution plot of sales, shows that, between 10 and 12, the values are higher"""

sns.pairplot(data=a)

"""Pie chart is plotted to show how the 3 media platforms are distributed"""

a_1=a['TV'].mean().round()
a_2=a['Radio'].mean().round()
a_3=a['Newspaper'].mean().round()
print(a_1,a_2,a_3)
T=a_1+a_2+a_3
print(T) # T for total
A=(a_1/T)*100
B=(a_2/T)*100
C=(a_3/T)*100
print(A,B,C) # individuals
plt.pie(x=[A,B,C],labels=['TV','Radio','Newspaper'])

"""From the above piechart, we can infer that the sales value of TV is the highest

**Data** **Preparation**
"""

# Due to the absence of text values, no dummy data is created

"""Dividing the data into input and output"""

x=a.drop(columns=['Sales']) # input column
y=a['Sales'] # output column

"""Standardising the data"""

# importing module for data standardisation
from sklearn.preprocessing import StandardScaler

s=StandardScaler()

# standardising the input column
x=pd.DataFrame(data=s.fit_transform(x),columns=x.columns) # x the inpt column has standardised values now.

"""Predictive Modelling

Since, the data is composed of continous variables, 2 algorithms are used for building the model - Linear Regression and K Nearest Regression
"""

# importing module for model building and training
from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2) # 80% data is to train the model and remaining 20% for testing

"""(1) Using Linear Regression"""

from sklearn.linear_model import LinearRegression

l1=LinearRegression() # defining a model

l1.fit(x_train,y_train)

# checking the accuracy of the model
l1.score(x_test,y_test)

"""(2) K Nearest Regression"""

from sklearn.neighbors import KNeighborsRegressor

k=KNeighborsRegressor(n_neighbors=2) # defining the model

k.fit(x_train,y_train) # training the model

k.score(x_test,y_test)

k_b=KNeighborsRegressor(n_neighbors=5) # checking b changing the number of neighbors
k_b.fit(x_train,y_train) # training the model
k_b.score(x_test,y_test)

"""Finding R2 score for choosing the better algorithm"""

# r2_score is imported
from sklearn.metrics import r2_score

y_pred=l1.predict(x_test) # for Linear Regression
print('R2 score of Linear Regression:',r2_score(y_test,y_pred))

y1_pred=k.predict(x_test) # for K Nearest Regression
print('R2 score of K Nearest Regression:',r2_score(y_test,y1_pred))

"""By comparing (1) and (2), K Nearest Regression with R2 score of 94 is found to be the suitable algorithm for the sales prediction.

So, K Nearest Regression algorithm is chosen to build the model for sales prediction
"""
